{
    "title": "AI Can’t Replace Teaching, but It Can Make It Better",
    "url": "https://www.wired.com/story/what-aspects-of-teaching-should-remain-human/",
    "publishedAt": "2024-07-10T11:30:00Z",
    "content": "To revisit this article, visit My Profile, then View saved stories.\nScience teacher Daniel Thompson circulated among his sixth graders at Ron Clark Academy, in Atlanta, on a recent spring morning, spot-checking their work and leading them into discussions about the day’s lessons on weather and water. He had a helper: a voice-activated AI that summoned apps and educational videos onto large-screen smartboards.\nWhen a student asked, “Are there any animals that don’t need water?” Thompson put the question to the AI. Within seconds, an illustrated blurb about kangaroo rats appeared before the class.\nThompson’s voice-activated assistant, Origin, is the brainchild of computer scientist Satya Nitta, who founded a company called Merlyn Mind after many years at IBM, where he had tried, and failed, to create an AI tool that could teach students directly. The foundation of that earlier, ill-fated project was IBM Watson, the AI that famously crushed several Jeopardy champions.\nDespite Watson’s game show success, it wasn’t very good at teaching students. After plowing five years and $100 million into the effort, the IBM team admitted defeat in 2017. “We realized the technology wasn’t there,” says Nitta. “And it’s still not there.”\nSince the November 2022 launch of OpenAI’s ChatGPT, an expanding cast of AI tutors and helpers is entering the learning landscape. Most of these tools are chatbots that tap large language models trained on troves of data to understand student inquiries and respond conversationally with a range of flexible and targeted learning assistance. These bots can generate quizzes, summarize key points in a complex reading, offer step-by-step graphing of algebraic equations, and provide feedback on the first draft of an essay, among other tasks.\nSome tools are subject-specific, such as Writable and Photomath, while others offer more all-purpose tutoring, such as Socratic (created by Google) and Khanmigo, an AI collaboration tool created by OpenAI and Khan Academy, a nonprofit provider of online lessons covering an array of academic subjects.\nAs more tools proliferate and their capabilities keep improving, relatively few observers believe education can remain AI free. At the same time, even the staunchest techno-optimists hesitate to say that teaching is best left to the bots. The debate is about the best mix.\nSkepticism about AI often centers on students using the technology to cut corners and on AI’s tendency to hallucinate, or to make stuff up in an eagerness to answer every query. The latter concern can be mitigated (albeit not eliminated) by measures like programming bots to base responses on vetted curricular materials. Less attention, however, is paid to an even thornier challenge for AI at the heart of effective teaching: engaging and motivating students.\nNitta says there’s something “deeply profound” about human communication that allows flesh-and-blood teachers to quickly spot and address things like confusion and flagging interest in real time.\nHe joins other experts in technology and education who believe AI’s best use is to augment and extend the reach of teachers, a vision that takes different forms. The goal of Origin, for example, is to make it easier for teachers to engage with students while also navigating apps and other digital teaching materials. Instead of being stationed by their computer, teachers can move around the class and interact with students, even the ones hoping to disappear in the back.\nOthers in education are trying to achieve this vision by using AI to help train tutors to have more productive student interactions, or by multiplying the number of students an instructor can engage with. Ultimately, these experts envision a partnership in which AI is called on not to be a teacher, but to supercharge the power of humans already doing the job.\nOrigin was piloted by thousands of teachers nationwide this past school year, including Thompson and three other teachers at Ron Clark Academy. The South Atlanta private school, where tuition is heavily subsidized for a majority low-income student body, is in a brick warehouse renovated to look like a low-rise Hogwarts, replete with an elaborate clocktower and a winged dragon perched above the main entrance.\nAs Thompson moved among his students, he wielded a slim remote control with a button-activated microphone, which he uses to command the AI software. At first, Thompson told the AI to start a three-minute timer that popped up on the smartboard. Then he began asking rapid-fire review questions from a previous lesson, such as, “What causes wind?” When students couldn’t remember the details, Thompson asked the AI to display an illustration of airflow caused by uneven heating of the Earth’s surface.\nAt one point, he clambered up on a student worktable while discussing the stratosphere, claiming (inaccurately) that it was the atmospheric layer where most weather happens, just to see whether any students caught his mistake (several students reminded him that weather happens in the troposphere). Then he conjured a new timer and launched into a lesson on water by asking the AI assistant to find a short educational movie about fresh and saltwater ecosystems. As Thompson moved through the class, he occasionally paused the video and quizzed students about the new content.\nStudies on student engagement, including research reviews released in 2018 in the journal Social Behavior and Personality and in 2020 by the Australian Journal of Teacher Education, have shown its importance for academic success. While AI has many strengths, Nitta says, “it’s not very good at motivating you to keep doing something you’re not very interested in doing.”\n“The elephant in the room with all these chatbots is, how long will anyone engage with them?” he says. He claims that in trials for Watson, students ignored its attempts to engage with them.\nAt a spring 2023 TED talk shortly after launching Khanmigo, Khan Academy founder and CEO Sal Khan pointed out that tutoring has provided some of the biggest jolts to student performance among studied education interventions. But there aren’t enough tutors available nor enough money to pay for them, especially in the wake of pandemic-induced learning loss.\nKhan Academy chief learning officer Kristen DiCerbo was the vice president of learning research and design for education publisher Pearson in 2016 when it partnered with IBM on Watson, which she describes as “a different technology” that was very reliant on scripted responses, in contrast to the unscripted interactions students can have with generative AI.\nKhanmigo doesn't answer student questions directly, but starts with questions of its own, such as asking whether the student has any ideas about how to find an answer. Then it guides them to a solution, step by step, with hints and encouragement.\nNotwithstanding Khan’s expansive vision of “amazing” personal tutors for every student on the planet, DiCerbo assigns Khanmigo a more limited teaching role. When students are working independently on a skill or concept but get hung up or caught in a cognitive rut, she says, “we want to help students get unstuck.”\nSome 100,000 students and teachers piloted Khanmigo this past academic year in schools nationwide, helping to flag any hallucinations the bot has and providing tons of student-bot conversations for DiCerbo and her team to analyze.\n“We look for things like summarizing, providing hints and encouraging,” she explains.\nThe degree to which Khanmigo has closed AI’s engagement gap is not yet known. Khan Academy plans to release some summary data on student-bot interactions later this summer, according to DiCerbo. Plans for third-party researchers to assess the tutor’s impact on learning will take longer.\nSince 2021, the nonprofit Saga Education has also been experimenting with AI feedback to help tutors better engage and motivate students. Working with researchers from the University of Memphis and the University of Colorado, the Saga team pilot in 2023 fed transcripts of their math tutoring sessions into an AI model trained to recognize when the tutor was prompting students to explain their reasoning, refine their answers, or initiate a deeper discussion. The AI analyzed how often each tutor took these steps.\nTracking some 2,300 tutoring sessions over several weeks, they found that tutors whose coaches used the AI feedback peppered their sessions with significantly more of these prompts to encourage student engagement.\nWhile Saga is looking into having AI deliver some feedback directly to tutors, it’s doing so cautiously because, according to Brent Milne, the vice president of product research and development at Saga Education, “having a human coach in the loop is really valuable to us.”\nExperts expect that AI’s role in education will grow, and its interactions will continue to seem more and more human. Earlier this year, OpenAI and the startup Hume AI separately launched “emotionally intelligent” AI that analyzes tone of voice and facial expressions to infer a user’s mood and respond with calibrated “empathy.” Nevertheless, even emotionally intelligent AI will likely fall short on the student engagement front, according to Brown University computer science professor Michael Littman, who is also the National Science Foundation’s division director for information and intelligent systems.\nNo matter how humanlike the conversation, he says, students understand at a fundamental level that AI doesn’t really care about them, what they have to say in their writing, or whether they pass or fail subjects. In turn, students will never really care about the bot and what it thinks. A June study in the journal Learning and Instruction found that AI can already provide decent feedback on student essays. What is not clear is whether student writers will put in care and effort, rather than offload the task to a bot, if AI becomes the primary audience for their work.\n“There’s incredible value in the human relationship component of learning,” Littman says, “and when you just take humans out of the equation, something is lost.”\nThis story about AI tutors was produced by The Hechinger Report, a nonprofit, independent news organization focused on inequality and innovation in education. Sign up for the Hechinger newsletter.\nIn your inbox: Our biggest stories, handpicked for you each day\nHow one bad CrowdStrike update crashed the world’s computers\nThe Big Story: How soon might the Atlantic Ocean break?\nWelcome to the internet's hyper-consumption era\nOlympics: Follow all our coverage from Paris this summer here\nMore From WIRED\nReviews and Guides\n© 2024 Condé Nast. All rights reserved. WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast. Ad Choices"
}